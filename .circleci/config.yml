# Use the latest 2.1 version of CircleCI pipeline process engine.
version: 2.1
commands:
  destroy-k8s:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      to:
        type: string
        default: "eks-Socialize"
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
              eksctl delete cluster --name=<<parameters.to>>
jobs:
  lint:
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - run:
          name: install and lint Dockerfile
          command: |
              cd ~/project
              sudo wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64
              sudo chmod +x /bin/hadolint
              sudo /bin/hadolint Dockerfile
  build_dockerfile:
    docker:
      - image: circleci/node:14
    steps:
      - checkout
      - restore_cache:
          keys: [build_docker]
      # - run:
      #     name: install dependencies
      #     command: yum install curl
      - setup_remote_docker
      - run: 
          name: build dockerfile
          command: |
              cd ~/project
              ls -ltr
              chmod +x run_docker.sh
              ./run_docker.sh
           
      - save_cache:
          paths: [/node_modules]
          key: build_docker

  deploy_to_kubernetes:
    docker:
      - image: circleci/python:3.7
    steps:
      - checkout
    
      - run:
          name: Install awscli and gettext-base
          command: |
            sudo pip3 install awscli
      - run:
          name: Install aws-iam-authenticator
          command: |
            curl -o aws-iam-authenticator curl -o aws-iam-authenticator https://amazon-eks.s3-us-west-2.amazonaws.com/1.13.7/2019-06-11/bin/linux/amd64/aws-iam-authenticator
            chmod +x ./aws-iam-authenticator
            sudo mv ./aws-iam-authenticator /usr/local/bin/aws-iam-authenticator
      - run:
          name: Install kubectl
          command: |
            curl -o kubectl https://amazon-eks.s3-us-west-2.amazonaws.com/1.13.7/2019-06-11/bin/linux/amd64/kubectl
            chmod +x ./kubectl
            sudo mv ./kubectl /usr/local/bin/kubectl
      - run:
          name: Install eksctl
          command: |
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
            sudo mv /tmp/eksctl /usr/local/bin
            eksctl version

      - setup_remote_docker
      - run:
          name: build docker image to ECR
          command: |
          
            aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${AWS_REPOSITORY_URL}
            docker build -t socialize .
            docker tag socialize:latest ${AWS_REPOSITORY_URL}/${REPOSITORY_NAME}:latest
            docker push ${AWS_REPOSITORY_URL}/${REPOSITORY_NAME}:latest
      # - run:
      #     name: setup vpc and subnets for k8s
      #     command: |
      #         aws cloudformation deploy --region us-east-1 --template-file ~/project/.circleci/eksserver_setup/server.yml --stack-name finalproj-${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Prepare K8S templates
          command: |
            eksctl create cluster -f ~/project/.circleci/k8s/cluster.yml --kubeconfig=~\.kube\config   
            aws eks --region ${AWS_DEFAULT_REGION} update-kubeconfig --name eks-Socialize
      - run:
          name: Deploy to EKS
          command: |
            kubectl create namespace default-socialize
            kubectl apply -n default-socialize -f ~/project/.circleci/k8s/deployment.yml
            kubectl get deployments
      - run:
          name: Accessing the Application
          command: |
              kubectl apply -n default-socialize -f ~/project/.circleci/k8s/service.yml
              # wait till the loadbalancer service is ready
              sleep 120
              kubectl get all --namespace default-socialize
      # - run: 
      #     name: Add port to EC2 nodePort SG
      #     command: |
      #       export SecurityGroups=$(aws ec2 describe-security-groups --filter Name=vpc-id,Values=vpc-01fb744229471cb5c Name=tag:Name,Values=eksctl-eks-Socialize-nodegroup-EKS-public-workers/SG --query 'SecurityGroups[*].[GroupId]' --no-paginate --output text)
      #       for sg in ${SecurityGroups}
      #         do
      #           aws ec2 authorize-security-group-ingress --group-id ${sg} --ip-permissions "[{\"IpProtocol\": \"tcp\", \"FromPort\": 31479, \"ToPort\": 31479,\"IpRanges\": [{ \"CidrIp\": \"0.0.0.0/0\"}]}]" 
      #       done 
      - run:
          name: Run k8s by port forwarding and Assign an fixed EIP to LoadBalancer IP
          command: |
              kubectl port-forward --address 0.0.0.0 service/webapp 3000:80 -n default-socialize > /dev/null 2>&1 &
              kubectl patch service webapp  -p '{"spec": {"type": "LoadBalancer", "externalIPs":["172.10.2.10"]}}'
              kubectl get services webapp
      
      - destroy-k8s

  smoke_test:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            pip3 install awscli
            apk add --update nodejs npm
            apk add curl
            curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
            mv /tmp/eksctl /usr/local/bin
            eksctl version
      - run:
          name: Get and test website url using the fixed EIP 
          command: |
              
              # export URL=$(aws ec2 describe-instances --filters Name=tag:Name,Values=eks-Socialize-EKS-public-workers-Node --query 'Reservations[0].Instances[0].PublicIpAddress' --output text)
              export WebUrl=http://172.10.2.10:3000/login
              curl ${WebUrl}
              # if [ curl ${WebUrl} | grep "Socialize" ]
              # then 
              #   return working
              # else
              #   return not working
              # fi
      # - destroy-k8s        
workflows:
  default:
    jobs:
      - lint
      - build_dockerfile:
            requires: [lint]
      - deploy_to_kubernetes:
            requires: [build_dockerfile]
      - smoke_test:
            requires: [deploy_to_kubernetes]

